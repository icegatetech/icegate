# Ingest Binary Configuration Example
#
# Copy this file to config.ingest.yaml and adjust the values for your environment.

# Catalog Configuration
catalog:
  # Catalog backend options:
  # - !memory (for testing)
  # - !rest { uri: "http://127.0.0.1:19120/iceberg" }
  # - !s3tables { table_bucket_arn: "arn:aws:s3tables:us-east-1:123456789012:bucket/my-bucket" }
  # - !glue {}
  # - !glue { catalog_id: "123456789012" }
  backend: !rest
    uri: http://127.0.0.1:19120/iceberg
  # Warehouse location (root path for data storage)
  warehouse: s3://warehouse
  # Additional catalog properties (optional)
  properties:
    prefix: main

# Storage Configuration
storage:
  # Storage backend options:
  # - !memory (for testing)
  # - !filesystem { root_path: "/var/lib/icegate/data" }
  # - !s3 { bucket: "warehouse", region: "us-east-1", endpoint: "https://..." }
  backend: !s3
    bucket: warehouse
    region: us-east-1
    endpoint: https://127.0.0.1:9100
  # Storage properties (optional)
  properties: {}

# Queue Configuration (WAL)
queue:
  common:
    # Base path for queue segments (e.g. s3://bucket/queue or file:///var/data/queue)
    base_path: s3://queue
    # Capacity of the write channel (bounded for backpressure)
    channel_capacity: 1024
    # Maximum number of rows in one WAL parquet row group
    max_row_group_size: 10000
  write:
    # Number of retry attempts for write operations
    write_retries: 3
    # Parquet compression codec: none, snappy, gzip, lzo, brotli, lz4, zstd
    compression: zstd
    # Flush by rows after this many row-groups-worth of accumulated rows
    records_per_flush_multiplier: 1
    # Maximum bytes to accumulate before flush
    max_bytes_per_flush: 67108864
    # Maximum time to wait before flush (milliseconds)
    flush_interval_ms: 1000
# Shift Configuration
shift:
  read:
    # max_record_batches_per_task: 128
    # max_input_bytes_per_task: 67108864
  write:
    # row_group_size: 10000
    # max_file_size_mb: 100
    # table_cache_ttl_secs: 60
  timeouts:
    # plan_base_ms: 60000
    # shift_base_ms: 120000
    # shift_per_record_batch_ms: 200
    # shift_per_segment_ms: 300
    # commit_base_ms: 30000
    # commit_per_parquet_file_ms: 100
  jobsmanager:
    # worker_count: 1
    # poll_interval_ms: 1000
    # iteration_interval_millisecs: 300
    storage:
      endpoint: http://127.0.0.1:9000
      bucket: jobs
      prefix: shifter
      region: us-east-1
      use_ssl: false
      job_state_codec: json
      request_timeout_secs: 5

# OTLP HTTP Server
otlp_http:
  enabled: true
  host: 127.0.0.1
  port: 4318

# OTLP gRPC Server
otlp_grpc:
  enabled: true
  host: 127.0.0.1
  port: 4317
